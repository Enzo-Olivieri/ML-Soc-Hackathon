{"metadata":{"kernelspec":{"display_name":"MLClass","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4679796,"sourceType":"datasetVersion","datasetId":2712039}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üèÜ Fake News Classification Mini-Hackathon üèÜ  \n\nWelcome to this exciting **Machine Learning Society Mini-Hackathon**, a collaboration between **Manu's Machine Learning Lectures** and the **Kaggle Team**!  \n\nüì∞ **Your Mission:** Build a model that can distinguish between **Fake News (1)** and **Real News (0)**.  \nüöÄ **Why Participate?** This is your chance to test your machine learning skills, experiment with NLP techniques, and compete against other talented individuals!  \n\nüí° **Key Challenge:** Fake news detection is a crucial task in today's world. Can your model accurately classify news articles based on their content?  \n\nLet‚Äôs get started! Good luck and happy coding! üéØ\n","metadata":{}},{"cell_type":"code","source":"# Let's import some basic libraries\n\nimport kagglehub\nimport os\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:04.850067Z","iopub.execute_input":"2025-03-20T17:55:04.850548Z","iopub.status.idle":"2025-03-20T17:55:04.856072Z","shell.execute_reply.started":"2025-03-20T17:55:04.850508Z","shell.execute_reply":"2025-03-20T17:55:04.854470Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Let's download the dataset!\n\npath = kagglehub.dataset_download(\"emineyetm/fake-news-detection-datasets\")\ndataset_path = path\n# print(\"Path to dataset files:\", path)\n# print(\"Dataset files:\", os.listdir(dataset_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:04.858068Z","iopub.execute_input":"2025-03-20T17:55:04.858581Z","iopub.status.idle":"2025-03-20T17:55:04.968165Z","shell.execute_reply.started":"2025-03-20T17:55:04.858494Z","shell.execute_reply":"2025-03-20T17:55:04.966843Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# üìä Data Exploration & Train-Test Split  \n\nBefore jumping into model training, let‚Äôs take a look at the dataset and the rules for this competition.  \n\n### **Dataset Overview**  \nThis dataset consists of **news articles**, each containing the following features:  \n- **Title:** The headline of the article.  \n- **Text:** The main content of the article.  \n- **Subject:** The category of the article (e.g., politics, world news, etc.).  \n- **Date:** The published date of the article.  \n- **Target:** The label indicating whether the news is **Fake (1)** or **Real (0)**.  \n\n### **Train-Test Split (75%-25%)**  \nFor this hackathon, we have **predefined** the dataset split:  \n- **Training Set (75%)** ‚Äì You **must only train** your models on this portion.  \n- **Test Set (25%)** ‚Äì This is used to evaluate the final model performance.  \n\n‚ö†Ô∏è **Important:** To ensure a fair competition, everyone should follow this split and avoid using test data for training.  \n\nExplore the dataset, check for missing values, understand the distributions, and let‚Äôs get ready to build some awesome models! üöÄ  \n","metadata":{}},{"cell_type":"code","source":"subdir_path = os.path.join(dataset_path, \"News _dataset\")  # Path to subdirectory\nprint(\"Files in subdirectory:\", os.listdir(subdir_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:04.970539Z","iopub.execute_input":"2025-03-20T17:55:04.970971Z","iopub.status.idle":"2025-03-20T17:55:04.979304Z","shell.execute_reply.started":"2025-03-20T17:55:04.970936Z","shell.execute_reply":"2025-03-20T17:55:04.977991Z"}},"outputs":[{"name":"stdout","text":"Files in subdirectory: ['True.csv', 'Fake.csv']\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"true_df = pd.read_csv(os.path.join(subdir_path, 'True.csv'))\ntrue_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:04.981090Z","iopub.execute_input":"2025-03-20T17:55:04.981558Z","iopub.status.idle":"2025-03-20T17:55:05.755790Z","shell.execute_reply.started":"2025-03-20T17:55:04.981515Z","shell.execute_reply":"2025-03-20T17:55:05.754605Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                   title  \\\n0      As U.S. budget fight looms, Republicans flip t...   \n1      U.S. military to accept transgender recruits o...   \n2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n3      FBI Russia probe helped by Australian diplomat...   \n4      Trump wants Postal Service to charge 'much mor...   \n...                                                  ...   \n21412  'Fully committed' NATO backs new U.S. approach...   \n21413  LexisNexis withdrew two products from Chinese ...   \n21414  Minsk cultural hub becomes haven from authorities   \n21415  Vatican upbeat on possibility of Pope Francis ...   \n21416  Indonesia to buy $1.14 billion worth of Russia...   \n\n                                                    text       subject  \\\n0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n...                                                  ...           ...   \n21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...     worldnews   \n21413  LONDON (Reuters) - LexisNexis, a provider of l...     worldnews   \n21414  MINSK (Reuters) - In the shadow of disused Sov...     worldnews   \n21415  MOSCOW (Reuters) - Vatican Secretary of State ...     worldnews   \n21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...     worldnews   \n\n                     date  \n0      December 31, 2017   \n1      December 29, 2017   \n2      December 31, 2017   \n3      December 30, 2017   \n4      December 29, 2017   \n...                   ...  \n21412    August 22, 2017   \n21413    August 22, 2017   \n21414    August 22, 2017   \n21415    August 22, 2017   \n21416    August 22, 2017   \n\n[21417 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n      <td>politicsNews</td>\n      <td>December 30, 2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21412</th>\n      <td>'Fully committed' NATO backs new U.S. approach...</td>\n      <td>BRUSSELS (Reuters) - NATO allies on Tuesday we...</td>\n      <td>worldnews</td>\n      <td>August 22, 2017</td>\n    </tr>\n    <tr>\n      <th>21413</th>\n      <td>LexisNexis withdrew two products from Chinese ...</td>\n      <td>LONDON (Reuters) - LexisNexis, a provider of l...</td>\n      <td>worldnews</td>\n      <td>August 22, 2017</td>\n    </tr>\n    <tr>\n      <th>21414</th>\n      <td>Minsk cultural hub becomes haven from authorities</td>\n      <td>MINSK (Reuters) - In the shadow of disused Sov...</td>\n      <td>worldnews</td>\n      <td>August 22, 2017</td>\n    </tr>\n    <tr>\n      <th>21415</th>\n      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n      <td>MOSCOW (Reuters) - Vatican Secretary of State ...</td>\n      <td>worldnews</td>\n      <td>August 22, 2017</td>\n    </tr>\n    <tr>\n      <th>21416</th>\n      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n      <td>JAKARTA (Reuters) - Indonesia will buy 11 Sukh...</td>\n      <td>worldnews</td>\n      <td>August 22, 2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>21417 rows √ó 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"fake_df = pd.read_csv(os.path.join(subdir_path, 'Fake.csv'))\nfake_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:05.756898Z","iopub.execute_input":"2025-03-20T17:55:05.757286Z","iopub.status.idle":"2025-03-20T17:55:06.599178Z","shell.execute_reply.started":"2025-03-20T17:55:05.757249Z","shell.execute_reply":"2025-03-20T17:55:06.598177Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                   title  \\\n0       Donald Trump Sends Out Embarrassing New Year‚Äô...   \n1       Drunk Bragging Trump Staffer Started Russian ...   \n2       Sheriff David Clarke Becomes An Internet Joke...   \n3       Trump Is So Obsessed He Even Has Obama‚Äôs Name...   \n4       Pope Francis Just Called Out Donald Trump Dur...   \n...                                                  ...   \n23476  McPain: John McCain Furious That Iran Treated ...   \n23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n23478  Sunnistan: US and Allied ‚ÄòSafe Zone‚Äô Plan to T...   \n23479  How to Blow $700 Million: Al Jazeera America F...   \n23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n\n                                                    text      subject  \\\n0      Donald Trump just couldn t wish all Americans ...         News   \n1      House Intelligence Committee Chairman Devin Nu...         News   \n2      On Friday, it was revealed that former Milwauk...         News   \n3      On Christmas day, Donald Trump announced that ...         News   \n4      Pope Francis used his annual Christmas Day mes...         News   \n...                                                  ...          ...   \n23476  21st Century Wire says As 21WIRE reported earl...  Middle-east   \n23477  21st Century Wire says It s a familiar theme. ...  Middle-east   \n23478  Patrick Henningsen  21st Century WireRemember ...  Middle-east   \n23479  21st Century Wire says Al Jazeera America will...  Middle-east   \n23480  21st Century Wire says As 21WIRE predicted in ...  Middle-east   \n\n                    date  \n0      December 31, 2017  \n1      December 31, 2017  \n2      December 30, 2017  \n3      December 29, 2017  \n4      December 25, 2017  \n...                  ...  \n23476   January 16, 2016  \n23477   January 16, 2016  \n23478   January 15, 2016  \n23479   January 14, 2016  \n23480   January 12, 2016  \n\n[23481 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Donald Trump Sends Out Embarrassing New Year‚Äô...</td>\n      <td>Donald Trump just couldn t wish all Americans ...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n      <td>House Intelligence Committee Chairman Devin Nu...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n      <td>On Friday, it was revealed that former Milwauk...</td>\n      <td>News</td>\n      <td>December 30, 2017</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trump Is So Obsessed He Even Has Obama‚Äôs Name...</td>\n      <td>On Christmas day, Donald Trump announced that ...</td>\n      <td>News</td>\n      <td>December 29, 2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n      <td>Pope Francis used his annual Christmas Day mes...</td>\n      <td>News</td>\n      <td>December 25, 2017</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23476</th>\n      <td>McPain: John McCain Furious That Iran Treated ...</td>\n      <td>21st Century Wire says As 21WIRE reported earl...</td>\n      <td>Middle-east</td>\n      <td>January 16, 2016</td>\n    </tr>\n    <tr>\n      <th>23477</th>\n      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n      <td>21st Century Wire says It s a familiar theme. ...</td>\n      <td>Middle-east</td>\n      <td>January 16, 2016</td>\n    </tr>\n    <tr>\n      <th>23478</th>\n      <td>Sunnistan: US and Allied ‚ÄòSafe Zone‚Äô Plan to T...</td>\n      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n      <td>Middle-east</td>\n      <td>January 15, 2016</td>\n    </tr>\n    <tr>\n      <th>23479</th>\n      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n      <td>21st Century Wire says Al Jazeera America will...</td>\n      <td>Middle-east</td>\n      <td>January 14, 2016</td>\n    </tr>\n    <tr>\n      <th>23480</th>\n      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n      <td>Middle-east</td>\n      <td>January 12, 2016</td>\n    </tr>\n  </tbody>\n</table>\n<p>23481 rows √ó 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"fake_df[\"target\"] = 1 # 1 = Fake News\ntrue_df[\"target\"] = 0 # 0 = True News\ndf = pd.concat([fake_df, true_df], ignore_index=True)\ndf = df.sample(frac=1, random_state=1).reset_index(drop=True) # Shuffle the dataset\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:06.600214Z","iopub.execute_input":"2025-03-20T17:55:06.600520Z","iopub.status.idle":"2025-03-20T17:55:06.637960Z","shell.execute_reply.started":"2025-03-20T17:55:06.600494Z","shell.execute_reply":"2025-03-20T17:55:06.636912Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                                   title  \\\n0       Trump Calls For This Racist Policy To Be Forc...   \n1      Republican ex-defense secretary Cohen backs Hi...   \n2      TEACHER QUITS JOB After 5th, 6th Grade Muslim ...   \n3      LAURA INGRAHAM RIPS INTO THE PRESS‚Ä¶Crowd Goes ...   \n4      Germany's Merkel suffers state vote setback as...   \n...                                                  ...   \n44893  Guatemala federal auditor to probe president's...   \n44894  House Democrats will stage sit-in until they g...   \n44895   D‚Äôoh!: Trump Tells Crowd In Richest County In...   \n44896  JUDGE JEANINE TELLS THE LEFT TO KNOCK IT OFF: ...   \n44897  Divided lawmakers battle over Puerto Rico debt...   \n\n                                                    text       subject  \\\n0      Donald Trump is calling for one of the most co...          News   \n1      WASHINGTON (Reuters) - Former Republican U.S. ...  politicsNews   \n2      You re never to young to commit jihad Teachers...      politics   \n3      Laura Ingraham reminds the Never Trump people ...      politics   \n4      BERLIN/HANOVER (Reuters) - Germany s Social De...     worldnews   \n...                                                  ...           ...   \n44893  GUATEMALA CITY (Reuters) - Guatemala s federal...     worldnews   \n44894  WASHINGTON (Reuters) - U.S. House of Represent...  politicsNews   \n44895  While in Virginia, GOP presidential nominee Do...          News   \n44896  Judge Jeanine Pirro has had it with the left a...      politics   \n44897  WASHINGTON (Reuters) - A congressional committ...  politicsNews   \n\n                      date  target  \n0       September 21, 2016       1  \n1       September 7, 2016        0  \n2              May 9, 2017       1  \n3             Jul 21, 2016       1  \n4        October 14, 2017        0  \n...                    ...     ...  \n44893  September 13, 2017        0  \n44894       June 22, 2016        0  \n44895       August 3, 2016       1  \n44896         Dec 11, 2016       1  \n44897        May 16, 2016        0  \n\n[44898 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trump Calls For This Racist Policy To Be Forc...</td>\n      <td>Donald Trump is calling for one of the most co...</td>\n      <td>News</td>\n      <td>September 21, 2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Republican ex-defense secretary Cohen backs Hi...</td>\n      <td>WASHINGTON (Reuters) - Former Republican U.S. ...</td>\n      <td>politicsNews</td>\n      <td>September 7, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEACHER QUITS JOB After 5th, 6th Grade Muslim ...</td>\n      <td>You re never to young to commit jihad Teachers...</td>\n      <td>politics</td>\n      <td>May 9, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LAURA INGRAHAM RIPS INTO THE PRESS‚Ä¶Crowd Goes ...</td>\n      <td>Laura Ingraham reminds the Never Trump people ...</td>\n      <td>politics</td>\n      <td>Jul 21, 2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Germany's Merkel suffers state vote setback as...</td>\n      <td>BERLIN/HANOVER (Reuters) - Germany s Social De...</td>\n      <td>worldnews</td>\n      <td>October 14, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44893</th>\n      <td>Guatemala federal auditor to probe president's...</td>\n      <td>GUATEMALA CITY (Reuters) - Guatemala s federal...</td>\n      <td>worldnews</td>\n      <td>September 13, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44894</th>\n      <td>House Democrats will stage sit-in until they g...</td>\n      <td>WASHINGTON (Reuters) - U.S. House of Represent...</td>\n      <td>politicsNews</td>\n      <td>June 22, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44895</th>\n      <td>D‚Äôoh!: Trump Tells Crowd In Richest County In...</td>\n      <td>While in Virginia, GOP presidential nominee Do...</td>\n      <td>News</td>\n      <td>August 3, 2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44896</th>\n      <td>JUDGE JEANINE TELLS THE LEFT TO KNOCK IT OFF: ...</td>\n      <td>Judge Jeanine Pirro has had it with the left a...</td>\n      <td>politics</td>\n      <td>Dec 11, 2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44897</th>\n      <td>Divided lawmakers battle over Puerto Rico debt...</td>\n      <td>WASHINGTON (Reuters) - A congressional committ...</td>\n      <td>politicsNews</td>\n      <td>May 16, 2016</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>44898 rows √ó 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"train_size = int(0.75 * len(df))\n\ntrain_df = df.iloc[:train_size]\ntest_df = df.iloc[train_size:]\n\nprint(\"Training set size:\", len(train_df))\nprint(\"Test set size:\", len(test_df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:06.638880Z","iopub.execute_input":"2025-03-20T17:55:06.639234Z","iopub.status.idle":"2025-03-20T17:55:06.646969Z","shell.execute_reply.started":"2025-03-20T17:55:06.639194Z","shell.execute_reply":"2025-03-20T17:55:06.645982Z"}},"outputs":[{"name":"stdout","text":"Training set size: 33673\nTest set size: 11225\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:06.647908Z","iopub.execute_input":"2025-03-20T17:55:06.648245Z","iopub.status.idle":"2025-03-20T17:55:06.674215Z","shell.execute_reply.started":"2025-03-20T17:55:06.648219Z","shell.execute_reply":"2025-03-20T17:55:06.673042Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                                   title  \\\n0       Trump Calls For This Racist Policy To Be Forc...   \n1      Republican ex-defense secretary Cohen backs Hi...   \n2      TEACHER QUITS JOB After 5th, 6th Grade Muslim ...   \n3      LAURA INGRAHAM RIPS INTO THE PRESS‚Ä¶Crowd Goes ...   \n4      Germany's Merkel suffers state vote setback as...   \n...                                                  ...   \n33668  Schumer says U.S. budget deal doable if Trump ...   \n33669  WOMAN PULLED OVER FOR 51 MPH IN SCHOOL ZONE: ‚Äú...   \n33670  INDIAN-AMERICAN, Inventor Of Email Announces R...   \n33671  Trump aides divided over policy shielding 'dre...   \n33672  WHY UNEDUCATED SOMALI REFUGEES Who Don‚Äôt Speak...   \n\n                                                    text       subject  \\\n0      Donald Trump is calling for one of the most co...          News   \n1      WASHINGTON (Reuters) - Former Republican U.S. ...  politicsNews   \n2      You re never to young to commit jihad Teachers...      politics   \n3      Laura Ingraham reminds the Never Trump people ...      politics   \n4      BERLIN/HANOVER (Reuters) - Germany s Social De...     worldnews   \n...                                                  ...           ...   \n33668  WASHINGTON (Reuters) - Senate Democratic Leade...  politicsNews   \n33669  I ve never been more grateful there are so man...     left-news   \n33670  Boston-based entrepreneur and inventor of Emai...      politics   \n33671  WASHINGTON (Reuters) - Divisions have emerged ...  politicsNews   \n33672  A few weeks ago, we reported on the first fema...      politics   \n\n                     date  target  \n0      September 21, 2016       1  \n1      September 7, 2016        0  \n2             May 9, 2017       1  \n3            Jul 21, 2016       1  \n4       October 14, 2017        0  \n...                   ...     ...  \n33668     April 23, 2017        0  \n33669        Sep 11, 2015       1  \n33670        Feb 25, 2017       1  \n33671   January 28, 2017        0  \n33672        Apr 29, 2017       1  \n\n[33673 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trump Calls For This Racist Policy To Be Forc...</td>\n      <td>Donald Trump is calling for one of the most co...</td>\n      <td>News</td>\n      <td>September 21, 2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Republican ex-defense secretary Cohen backs Hi...</td>\n      <td>WASHINGTON (Reuters) - Former Republican U.S. ...</td>\n      <td>politicsNews</td>\n      <td>September 7, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEACHER QUITS JOB After 5th, 6th Grade Muslim ...</td>\n      <td>You re never to young to commit jihad Teachers...</td>\n      <td>politics</td>\n      <td>May 9, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LAURA INGRAHAM RIPS INTO THE PRESS‚Ä¶Crowd Goes ...</td>\n      <td>Laura Ingraham reminds the Never Trump people ...</td>\n      <td>politics</td>\n      <td>Jul 21, 2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Germany's Merkel suffers state vote setback as...</td>\n      <td>BERLIN/HANOVER (Reuters) - Germany s Social De...</td>\n      <td>worldnews</td>\n      <td>October 14, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33668</th>\n      <td>Schumer says U.S. budget deal doable if Trump ...</td>\n      <td>WASHINGTON (Reuters) - Senate Democratic Leade...</td>\n      <td>politicsNews</td>\n      <td>April 23, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33669</th>\n      <td>WOMAN PULLED OVER FOR 51 MPH IN SCHOOL ZONE: ‚Äú...</td>\n      <td>I ve never been more grateful there are so man...</td>\n      <td>left-news</td>\n      <td>Sep 11, 2015</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33670</th>\n      <td>INDIAN-AMERICAN, Inventor Of Email Announces R...</td>\n      <td>Boston-based entrepreneur and inventor of Emai...</td>\n      <td>politics</td>\n      <td>Feb 25, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33671</th>\n      <td>Trump aides divided over policy shielding 'dre...</td>\n      <td>WASHINGTON (Reuters) - Divisions have emerged ...</td>\n      <td>politicsNews</td>\n      <td>January 28, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33672</th>\n      <td>WHY UNEDUCATED SOMALI REFUGEES Who Don‚Äôt Speak...</td>\n      <td>A few weeks ago, we reported on the first fema...</td>\n      <td>politics</td>\n      <td>Apr 29, 2017</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>33673 rows √ó 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"# üöÄ Start Your Submission Here!  \n\nNow it‚Äôs your turn to shine! ‚ú®  \n\nüìå **Instructions:**  \n- Implement your **feature engineering** and **model training** below.  \n- Remember to use only the **75% training set** for training your model.  \n- Test your model on the **25% test set** and analyze its performance.  \n\nüí° **Pro Tip:** Try experimenting with different NLP techniques (TF-IDF, Word Embeddings, Transformers) to boost your model‚Äôs accuracy!  \n\nBest of luck! üéØ Let‚Äôs see who builds the most accurate Fake News Classifier! üèÜ  \n","metadata":{}},{"cell_type":"code","source":"# Sample submission\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:06.677178Z","iopub.execute_input":"2025-03-20T17:55:06.677504Z","iopub.status.idle":"2025-03-20T17:55:07.524168Z","shell.execute_reply.started":"2025-03-20T17:55:06.677476Z","shell.execute_reply":"2025-03-20T17:55:07.523032Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"train_df = train_df.copy()\ntest_df = test_df.copy()\n\ntrain_df[\"content\"] = train_df[\"title\"] + \" \" + train_df[\"subject\"] + \" \" + train_df[\"text\"] \ntest_df[\"content\"] = test_df[\"title\"] + \" \" + test_df[\"subject\"] + \" \" + test_df[\"text\"] \n\nprint(\"Training set size:\", len(train_df))\nprint(\"Test set size:\", len(test_df))\n\nvectorizer = TfidfVectorizer(max_features=100000)\n\nX_train = vectorizer.fit_transform(train_df[\"content\"])\nX_test = vectorizer.transform(test_df[\"content\"])\n\ny_train = train_df[\"target\"]\ny_test = test_df[\"target\"]\n\nmodel = LogisticRegression(max_iter=100000)\nmodel.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:07.525350Z","iopub.execute_input":"2025-03-20T17:55:07.525881Z","iopub.status.idle":"2025-03-20T17:55:26.250375Z","shell.execute_reply.started":"2025-03-20T17:55:07.525849Z","shell.execute_reply":"2025-03-20T17:55:26.249334Z"}},"outputs":[{"name":"stdout","text":"Training set size: 33673\nTest set size: 11225\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(max_iter=100000)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=100000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=100000)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"# üèÜ Test Your Accuracy Here!  \n\nNow that you've trained your model, let's see how well it performs! üöÄ  \n\nüìå **Instructions:**  \n- Use the **test set (25%)** to make predictions.  \n- Compare your predictions against the actual labels.  \n- Calculate the **accuracy** score to evaluate performance.  \n\nüìä **Accuracy Calculation:**  \n$$\n\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n$$\n\nüöÄ **Submit your final accuracy score below and see how you rank!** üî•  ","metadata":{}},{"cell_type":"code","source":"\npredictions = model.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Test Accuracy:\", accuracy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:26.251457Z","iopub.execute_input":"2025-03-20T17:55:26.251850Z","iopub.status.idle":"2025-03-20T17:55:26.269544Z","shell.execute_reply.started":"2025-03-20T17:55:26.251814Z","shell.execute_reply":"2025-03-20T17:55:26.268479Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.98913140311804\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"### Zero-Shot Classification Models","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Initialize a zero-shot classification pipeline\nclassifier = pipeline(\"zero-shot-classification\", \n                      model=\"facebook/bart-large-mnli\")\n\n# Example text to classify\nsequence_to_classify = \"This article claims that the Earth is flat.\"\n\n# Candidate labels (possible categories for classification)\ncandidate_labels = [\"fake news\", \"real news\", \"misleading\", \"conspiracy\"]\n\n# Run inference\nresult = classifier(sequence_to_classify, candidate_labels)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:55:26.270977Z","iopub.execute_input":"2025-03-20T17:55:26.271359Z","iopub.status.idle":"2025-03-20T17:56:06.932530Z","shell.execute_reply.started":"2025-03-20T17:55:26.271320Z","shell.execute_reply":"2025-03-20T17:56:06.931452Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6659e2220f014d2da8d16bb9e54c1cd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec2bbe21df3644d09d08a977baadc2ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54425ba347634dbbafdb1b402994f2d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7aa0a906e3d4566b5a4d3490428ff72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"992778f325a44054bafb69d1ec488289"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d495fb27e1a443a895c9b0ee75c05ea2"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"{'sequence': 'This article claims that the Earth is flat.', 'labels': ['misleading', 'conspiracy', 'fake news', 'real news'], 'scores': [0.6637750864028931, 0.14953134953975677, 0.12464383244514465, 0.062049709260463715]}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Initialize zero-shot classification pipeline with a lightweight model\nclassifier = pipeline(\"zero-shot-classification\", \n                      model=\"typeform/distilbert-base-uncased-mnli\")\n\n# Example text to classify\nsequence_to_classify = \"This article asserts that climate change is a hoax.\"\n\n# Candidate labels for classification\ncandidate_labels = [\"fake news\", \"real news\", \"misleading\", \"conspiracy\"]\n\n# Run inference\nresult = classifier(sequence_to_classify, candidate_labels)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:56:06.933652Z","iopub.execute_input":"2025-03-20T17:56:06.934469Z","iopub.status.idle":"2025-03-20T17:56:09.619080Z","shell.execute_reply.started":"2025-03-20T17:56:06.934425Z","shell.execute_reply":"2025-03-20T17:56:09.618002Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c60386288c8f4452a5f7d1205d0a4750"}},"metadata":{}},{"name":"stderr","text":"The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc14118bf1b4c17a3b0e087a58c26d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/258 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5283428e7cf54215b33f2272be4d9091"}},"metadata":{}},{"name":"stderr","text":"The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"777a9f49476a46028ed11239cbb6dff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55eefb613fd04ab8945a60653ba8d076"}},"metadata":{}},{"name":"stderr","text":"The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nDevice set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"{'sequence': 'This article asserts that climate change is a hoax.', 'labels': ['fake news', 'misleading', 'conspiracy', 'real news'], 'scores': [0.6349366307258606, 0.36300691962242126, 0.0016185108106583357, 0.0004378522571641952]}\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Initialize zero-shot classification pipeline with a distilled BART model\nclassifier = pipeline(\"zero-shot-classification\", \n                      model=\"valhalla/distilbart-mnli-12-3\")\n\n# Example text to classify\nsequence_to_classify = \"This report claims that a cure for the common cold has been discovered.\"\n\n# Candidate labels for classification\ncandidate_labels = [\"fake news\", \"real news\", \"misleading\", \"conspiracy\"]\n\n# Run inference\nresult = classifier(sequence_to_classify, candidate_labels)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T17:56:09.620293Z","iopub.execute_input":"2025-03-20T17:56:09.620711Z","iopub.status.idle":"2025-03-20T17:56:17.250076Z","shell.execute_reply.started":"2025-03-20T17:56:09.620670Z","shell.execute_reply":"2025-03-20T17:56:17.248712Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6428eebfd2144c89671e42047f52a09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"addb861c5d0a4513bd479daba555c8b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6f78344dcfe45c19d877e783d91aaf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67cbef331f214fcd9a795f3256f0a078"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6c6846df60e4266a1dae16d7c4cf568"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7791c7a819b14e0dadeb965932e2fe6c"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"{'sequence': 'This report claims that a cure for the common cold has been discovered.', 'labels': ['misleading', 'fake news', 'real news', 'conspiracy'], 'scores': [0.6190851330757141, 0.17369163036346436, 0.12602326273918152, 0.08119994401931763]}\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"#Trying title only\ntrain_df[\"title\"]\n#train_title_only = ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:03:57.928829Z","iopub.execute_input":"2025-03-20T18:03:57.929194Z","iopub.status.idle":"2025-03-20T18:03:57.937085Z","shell.execute_reply.started":"2025-03-20T18:03:57.929166Z","shell.execute_reply":"2025-03-20T18:03:57.935918Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0         Trump Calls For This Racist Policy To Be Forc...\n1        Republican ex-defense secretary Cohen backs Hi...\n2        TEACHER QUITS JOB After 5th, 6th Grade Muslim ...\n3        LAURA INGRAHAM RIPS INTO THE PRESS‚Ä¶Crowd Goes ...\n4        Germany's Merkel suffers state vote setback as...\n                               ...                        \n33668    Schumer says U.S. budget deal doable if Trump ...\n33669    WOMAN PULLED OVER FOR 51 MPH IN SCHOOL ZONE: ‚Äú...\n33670    INDIAN-AMERICAN, Inventor Of Email Announces R...\n33671    Trump aides divided over policy shielding 'dre...\n33672    WHY UNEDUCATED SOMALI REFUGEES Who Don‚Äôt Speak...\nName: title, Length: 33673, dtype: object"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"## Create separate data sets","metadata":{}},{"cell_type":"code","source":"train_title_df = train_df[\"title\"]\ntrain_text_df = train_df[\"text\"]\ntest_title_df = test_df[\"title\"]\ntest_text_df = test_df[\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:22:04.059761Z","iopub.execute_input":"2025-03-20T18:22:04.060174Z","iopub.status.idle":"2025-03-20T18:22:04.065480Z","shell.execute_reply.started":"2025-03-20T18:22:04.060141Z","shell.execute_reply":"2025-03-20T18:22:04.064321Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"test_title_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:22:04.749737Z","iopub.execute_input":"2025-03-20T18:22:04.750464Z","iopub.status.idle":"2025-03-20T18:22:04.759112Z","shell.execute_reply.started":"2025-03-20T18:22:04.750371Z","shell.execute_reply":"2025-03-20T18:22:04.758067Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"33673    Trump reelection campaign raised $10 million i...\n33674    TV Reporter FIRED After Being Caught On Video ...\n33675     BREAKING: Dakota Access Pipeline STOPPED By A...\n33676    Trump says he did not record conversations wit...\n33677    Top Russian and U.S. generals discuss Syria bo...\n                               ...                        \n44893    Guatemala federal auditor to probe president's...\n44894    House Democrats will stage sit-in until they g...\n44895     D‚Äôoh!: Trump Tells Crowd In Richest County In...\n44896    JUDGE JEANINE TELLS THE LEFT TO KNOCK IT OFF: ...\n44897    Divided lawmakers battle over Puerto Rico debt...\nName: title, Length: 11225, dtype: object"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"y_train = train_df[\"target\"]\ny_test = test_df[\"target\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features=100000)\n\ntrain_title_df = vectorizer.fit_transform(train_title_df)\ntest_title_df = vectorizer.transform(test_title_df)\n\nmodel = LogisticRegression(max_iter=100000)\nmodel.fit(train_title_df, y_train)\n\npredictions = model.predict(test_title_df)\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:22:05.185902Z","iopub.execute_input":"2025-03-20T18:22:05.186367Z","iopub.status.idle":"2025-03-20T18:22:06.147576Z","shell.execute_reply.started":"2025-03-20T18:22:05.186334Z","shell.execute_reply":"2025-03-20T18:22:06.146383Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9510022271714922\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Preprocessing Function\ndef preprocess_text(text):\n    # Lowercase\n    text = text.lower()\n    # Remove special characters and numbers\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    # Tokenize and Lemmatize\n    lemmatizer = WordNetLemmatizer()\n    words = text.split()\n    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words('english')]\n    return \" \".join(words)\n\n# Apply preprocessing to the raw text before vectorization\ntrain_text_df = train_text_df.apply(preprocess_text)\ntest_text_df = test_text_df.apply(preprocess_text)\n\n# Now, apply TfidfVectorizer to the preprocessed text\nvectorizer = TfidfVectorizer(max_features=100000)\ntrain_text_df = vectorizer.fit_transform(train_text_df)\ntest_text_df = vectorizer.transform(test_text_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:31:48.516682Z","iopub.execute_input":"2025-03-20T18:31:48.517066Z","iopub.status.idle":"2025-03-20T18:31:48.559330Z","shell.execute_reply.started":"2025-03-20T18:31:48.517039Z","shell.execute_reply":"2025-03-20T18:31:48.557286Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-0ff0ddb64c4a>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Apply preprocessing to the raw text before vectorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_text_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_text_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mtest_text_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_text_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'csr_matrix' object has no attribute 'apply'"],"ename":"AttributeError","evalue":"'csr_matrix' object has no attribute 'apply'","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"model = LogisticRegression(max_iter=100000)\nmodel.fit(train_text_df, y_train)\n\npredictions = model.predict(test_text_df)\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features=100000)\n\ntrain_text_df = vectorizer.fit_transform(train_text_df)\ntest_text_df = vectorizer.transform(test_text_df)\n\nmodel = LogisticRegression(max_iter=100000)\nmodel.fit(train_text_df, y_train)\n\npredictions = model.predict(test_text_df)\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:23:32.688793Z","iopub.execute_input":"2025-03-20T18:23:32.689184Z","iopub.status.idle":"2025-03-20T18:23:51.900281Z","shell.execute_reply.started":"2025-03-20T18:23:32.689156Z","shell.execute_reply":"2025-03-20T18:23:51.899279Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9856570155902005\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Initialize CatBoostClassifier\ncatboost_model = CatBoostClassifier(iterations=1000, depth=10, learning_rate=0.05, loss_function='Logloss', verbose=200)\n\n# Train the model\ncatboost_model.fit(train_title_df, y_train)\n\n# Make predictions\ncatboost_predictions = catboost_model.predict(test_title_df)\n\n# Calculate accuracy\ncatboost_accuracy = accuracy_score(y_test, catboost_predictions)\nprint(\"CatBoost Test Accuracy:\", catboost_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:26:11.195327Z","iopub.execute_input":"2025-03-20T18:26:11.196029Z","iopub.status.idle":"2025-03-20T18:28:08.749971Z","shell.execute_reply.started":"2025-03-20T18:26:11.195984Z","shell.execute_reply":"2025-03-20T18:28:08.748344Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 0.6496842\ttotal: 2.3s\tremaining: 38m 21s\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-390dd466f581>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcatboost_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_title_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5243\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5245\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5246\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5247\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m                 self._train(\n\u001b[0m\u001b[1;32m   2411\u001b[0m                     \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m                     \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":40},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Initialize Random Forest Classifier\nrf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n\n# Train the model\nrf_model.fit(train_title_df, y_train)\n\n# Make predictions\nrf_predictions = rf_model.predict(test_title_df)\n\n# Calculate accuracy\nrf_accuracy = accuracy_score(y_test, rf_predictions)\nprint(\"Random Forest Test Accuracy:\", rf_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:28:12.631017Z","iopub.execute_input":"2025-03-20T18:28:12.631382Z","iopub.status.idle":"2025-03-20T18:28:14.983991Z","shell.execute_reply.started":"2025-03-20T18:28:12.631352Z","shell.execute_reply":"2025-03-20T18:28:14.982706Z"}},"outputs":[{"name":"stdout","text":"Random Forest Test Accuracy: 0.8824944320712695\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Initialize XGBoost Classifier\nxgb_model = XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=10, random_state=42)\n\n# Train the model\nxgb_model.fit(train_title_df, y_train)\n\n# Make predictions\nxgb_predictions = xgb_model.predict(test_title_df)\n\n# Calculate accuracy\nxgb_accuracy = accuracy_score(y_test, xgb_predictions)\nprint(\"XGBoost Test Accuracy:\", xgb_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:28:17.558988Z","iopub.execute_input":"2025-03-20T18:28:17.559330Z","iopub.status.idle":"2025-03-20T18:28:56.952373Z","shell.execute_reply.started":"2025-03-20T18:28:17.559305Z","shell.execute_reply":"2025-03-20T18:28:56.951099Z"}},"outputs":[{"name":"stdout","text":"XGBoost Test Accuracy: 0.9123385300668151\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nltk.download()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:35:40.356550Z","iopub.execute_input":"2025-03-20T18:35:40.356907Z","iopub.status.idle":"2025-03-20T18:39:39.689063Z","shell.execute_reply.started":"2025-03-20T18:35:40.356877Z","shell.execute_reply":"2025-03-20T18:39:39.687013Z"}},"outputs":[{"name":"stdout","text":"NLTK Downloader\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Downloader>  d\n"},{"name":"stdout","text":"\nDownload which package (l=list; x=cancel)?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Identifier>  l\n"},{"name":"stdout","text":"Packages:\n  [ ] averaged_perceptron_tagger_eng Averaged Perceptron Tagger (JSON)\n  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n  [ ] averaged_perceptron_tagger_rus Averaged Perceptron Tagger (Russian)\n  [ ] bcp47............... BCP-47 Language Tags\n  [ ] comparative_sentences Comparative Sentence Dataset\n  [ ] dolch............... Dolch Word List\n  [ ] english_wordnet..... Open English Wordnet\n  [ ] extended_omw........ Extended Open Multilingual WordNet\n  [ ] framenet_v15........ FrameNet 1.5\n  [ ] framenet_v17........ FrameNet 1.7\n  [-] inaugural........... C-Span Inaugural Address Corpus\n  [ ] maxent_ne_chunker_tab ACE Named Entity Chunker (Maximum entropy)\n  [ ] maxent_treebank_pos_tagger_tab Treebank Part of Speech Tagger (Maximum entropy)\n  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n                           2015) subset of the Paraphrase Database.\n  [ ] nombank.1.0......... NomBank Corpus 1.0\n  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n  [ ] omw-1.4............. Open Multilingual Wordnet\n  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n                           Evaluation Shared Task\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Hit Enter to continue:  \n"},{"name":"stdout","text":"  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n                           character properties in Perl\n  [ ] punkt_tab........... Punkt Tokenizer Models\n  [ ] tagsets_json........ Help on Tagsets (JSON)\n  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n  [ ] wmt15_eval.......... Evaluation data from WMT15\n  [ ] wordnet2021......... Open English Wordnet 2021\n  [ ] wordnet2022......... Open English Wordnet 2022\n  [ ] wordnet31........... Wordnet 3.1\n\nCollections:\n  [-] all-corpora......... All the corpora\n  [-] all-nltk............ All packages available on nltk_data gh-pages\n                           branch\n  [-] all................. All packages\n  [-] book................ Everything used in the NLTK Book\n  [-] popular............. Popular packages\n  [P] tests............... Packages for running tests\n  [ ] third-party......... Third-party data packages\n\n([*] marks installed packages; [-] marks out-of-date or corrupt packages;\n [P] marks partially installed collections)\n\nDownload which package (l=list; x=cancel)?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Identifier>  l\n"},{"name":"stdout","text":"Packages:\n  [ ] averaged_perceptron_tagger_eng Averaged Perceptron Tagger (JSON)\n  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n  [ ] averaged_perceptron_tagger_rus Averaged Perceptron Tagger (Russian)\n  [ ] bcp47............... BCP-47 Language Tags\n  [ ] comparative_sentences Comparative Sentence Dataset\n  [ ] dolch............... Dolch Word List\n  [ ] english_wordnet..... Open English Wordnet\n  [ ] extended_omw........ Extended Open Multilingual WordNet\n  [ ] framenet_v15........ FrameNet 1.5\n  [ ] framenet_v17........ FrameNet 1.7\n  [-] inaugural........... C-Span Inaugural Address Corpus\n  [ ] maxent_ne_chunker_tab ACE Named Entity Chunker (Maximum entropy)\n  [ ] maxent_treebank_pos_tagger_tab Treebank Part of Speech Tagger (Maximum entropy)\n  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n                           2015) subset of the Paraphrase Database.\n  [ ] nombank.1.0......... NomBank Corpus 1.0\n  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n  [ ] omw-1.4............. Open Multilingual Wordnet\n  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n                           Evaluation Shared Task\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Hit Enter to continue:  \n"},{"name":"stdout","text":"  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n                           character properties in Perl\n  [ ] punkt_tab........... Punkt Tokenizer Models\n  [ ] tagsets_json........ Help on Tagsets (JSON)\n  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n  [ ] wmt15_eval.......... Evaluation data from WMT15\n  [ ] wordnet2021......... Open English Wordnet 2021\n  [ ] wordnet2022......... Open English Wordnet 2022\n  [ ] wordnet31........... Wordnet 3.1\n\nCollections:\n  [-] all-corpora......... All the corpora\n  [-] all-nltk............ All packages available on nltk_data gh-pages\n                           branch\n  [-] all................. All packages\n  [-] book................ Everything used in the NLTK Book\n  [-] popular............. Popular packages\n  [P] tests............... Packages for running tests\n  [ ] third-party......... Third-party data packages\n\n([*] marks installed packages; [-] marks out-of-date or corrupt packages;\n [P] marks partially installed collections)\n\nDownload which package (l=list; x=cancel)?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Identifier>  all-nltk\n"},{"name":"stdout","text":"    Downloading collection 'all-nltk'\n       | \n       | Downloading package abc to /usr/share/nltk_data...\n       |   Package abc is already up-to-date!\n       | Downloading package alpino to /usr/share/nltk_data...\n       |   Package alpino is already up-to-date!\n       | Downloading package averaged_perceptron_tagger to\n       |     /usr/share/nltk_data...\n       |   Package averaged_perceptron_tagger is already up-to-date!\n       | Downloading package averaged_perceptron_tagger_eng to\n       |     /usr/share/nltk_data...\n       |   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n       | Downloading package averaged_perceptron_tagger_ru to\n       |     /usr/share/nltk_data...\n       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n       | Downloading package averaged_perceptron_tagger_rus to\n       |     /usr/share/nltk_data...\n       |   Unzipping taggers/averaged_perceptron_tagger_rus.zip.\n       | Downloading package basque_grammars to\n       |     /usr/share/nltk_data...\n       |   Package basque_grammars is already up-to-date!\n       | Downloading package bcp47 to /usr/share/nltk_data...\n       | Downloading package biocreative_ppi to\n       |     /usr/share/nltk_data...\n       |   Package biocreative_ppi is already up-to-date!\n       | Downloading package bllip_wsj_no_aux to\n       |     /usr/share/nltk_data...\n       |   Package bllip_wsj_no_aux is already up-to-date!\n       | Downloading package book_grammars to /usr/share/nltk_data...\n       |   Package book_grammars is already up-to-date!\n       | Downloading package brown to /usr/share/nltk_data...\n       |   Package brown is already up-to-date!\n       | Downloading package brown_tei to /usr/share/nltk_data...\n       |   Package brown_tei is already up-to-date!\n       | Downloading package cess_cat to /usr/share/nltk_data...\n       |   Package cess_cat is already up-to-date!\n       | Downloading package cess_esp to /usr/share/nltk_data...\n       |   Package cess_esp is already up-to-date!\n       | Downloading package chat80 to /usr/share/nltk_data...\n       |   Package chat80 is already up-to-date!\n       | Downloading package city_database to /usr/share/nltk_data...\n       |   Package city_database is already up-to-date!\n       | Downloading package cmudict to /usr/share/nltk_data...\n       |   Package cmudict is already up-to-date!\n       | Downloading package comparative_sentences to\n       |     /usr/share/nltk_data...\n       |   Unzipping corpora/comparative_sentences.zip.\n       | Downloading package comtrans to /usr/share/nltk_data...\n       |   Package comtrans is already up-to-date!\n       | Downloading package conll2000 to /usr/share/nltk_data...\n       |   Package conll2000 is already up-to-date!\n       | Downloading package conll2002 to /usr/share/nltk_data...\n       |   Package conll2002 is already up-to-date!\n       | Downloading package conll2007 to /usr/share/nltk_data...\n       |   Package conll2007 is already up-to-date!\n       | Downloading package crubadan to /usr/share/nltk_data...\n       |   Package crubadan is already up-to-date!\n       | Downloading package dependency_treebank to\n       |     /usr/share/nltk_data...\n       |   Package dependency_treebank is already up-to-date!\n       | Downloading package dolch to /usr/share/nltk_data...\n       |   Unzipping corpora/dolch.zip.\n       | Downloading package english_wordnet to\n       |     /usr/share/nltk_data...\n       |   Unzipping corpora/english_wordnet.zip.\n       | Downloading package europarl_raw to /usr/share/nltk_data...\n       |   Package europarl_raw is already up-to-date!\n       | Downloading package extended_omw to /usr/share/nltk_data...\n       | Downloading package floresta to /usr/share/nltk_data...\n       |   Package floresta is already up-to-date!\n       | Downloading package framenet_v15 to /usr/share/nltk_data...\n       |   Unzipping corpora/framenet_v15.zip.\n       | Downloading package framenet_v17 to /usr/share/nltk_data...\n       |   Unzipping corpora/framenet_v17.zip.\n       | Downloading package gazetteers to /usr/share/nltk_data...\n       |   Package gazetteers is already up-to-date!\n       | Downloading package genesis to /usr/share/nltk_data...\n       |   Package genesis is already up-to-date!\n       | Downloading package gutenberg to /usr/share/nltk_data...\n       |   Package gutenberg is already up-to-date!\n       | Downloading package ieer to /usr/share/nltk_data...\n       |   Package ieer is already up-to-date!\n       | Downloading package inaugural to /usr/share/nltk_data...\n       |   Unzipping corpora/inaugural.zip.\n       | Downloading package indian to /usr/share/nltk_data...\n       |   Package indian is already up-to-date!\n       | Downloading package jeita to /usr/share/nltk_data...\n       |   Package jeita is already up-to-date!\n       | Downloading package kimmo to /usr/share/nltk_data...\n       |   Package kimmo is already up-to-date!\n       | Downloading package knbc to /usr/share/nltk_data...\n       |   Package knbc is already up-to-date!\n       | Downloading package large_grammars to /usr/share/nltk_data...\n       |   Package large_grammars is already up-to-date!\n       | Downloading package lin_thesaurus to /usr/share/nltk_data...\n       |   Package lin_thesaurus is already up-to-date!\n       | Downloading package mac_morpho to /usr/share/nltk_data...\n       |   Package mac_morpho is already up-to-date!\n       | Downloading package machado to /usr/share/nltk_data...\n       |   Package machado is already up-to-date!\n       | Downloading package masc_tagged to /usr/share/nltk_data...\n       |   Package masc_tagged is already up-to-date!\n       | Downloading package maxent_ne_chunker to\n       |     /usr/share/nltk_data...\n       |   Package maxent_ne_chunker is already up-to-date!\n       | Downloading package maxent_ne_chunker_tab to\n       |     /usr/share/nltk_data...\n       |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n       | Downloading package maxent_treebank_pos_tagger to\n       |     /usr/share/nltk_data...\n       |   Package maxent_treebank_pos_tagger is already up-to-date!\n       | Downloading package maxent_treebank_pos_tagger_tab to\n       |     /usr/share/nltk_data...\n       |   Unzipping taggers/maxent_treebank_pos_tagger_tab.zip.\n       | Downloading package moses_sample to /usr/share/nltk_data...\n       |   Package moses_sample is already up-to-date!\n       | Downloading package movie_reviews to /usr/share/nltk_data...\n       |   Package movie_reviews is already up-to-date!\n       | Downloading package mte_teip5 to /usr/share/nltk_data...\n       |   Package mte_teip5 is already up-to-date!\n       | Downloading package mwa_ppdb to /usr/share/nltk_data...\n       |   Unzipping misc/mwa_ppdb.zip.\n       | Downloading package names to /usr/share/nltk_data...\n       |   Package names is already up-to-date!\n       | Downloading package nombank.1.0 to /usr/share/nltk_data...\n       | Downloading package nonbreaking_prefixes to\n       |     /usr/share/nltk_data...\n       |   Unzipping corpora/nonbreaking_prefixes.zip.\n       | Downloading package nps_chat to /usr/share/nltk_data...\n       |   Package nps_chat is already up-to-date!\n       | Downloading package omw to /usr/share/nltk_data...\n       |   Package omw is already up-to-date!\n       | Downloading package omw-1.4 to /usr/share/nltk_data...\n       | Downloading package opinion_lexicon to\n       |     /usr/share/nltk_data...\n       |   Package opinion_lexicon is already up-to-date!\n       | Downloading package panlex_swadesh to /usr/share/nltk_data...\n       | Downloading package paradigms to /usr/share/nltk_data...\n       |   Package paradigms is already up-to-date!\n       | Downloading package pe08 to /usr/share/nltk_data...\n       |   Unzipping corpora/pe08.zip.\n       | Downloading package perluniprops to /usr/share/nltk_data...\n       |   Unzipping misc/perluniprops.zip.\n       | Downloading package pil to /usr/share/nltk_data...\n       |   Package pil is already up-to-date!\n       | Downloading package pl196x to /usr/share/nltk_data...\n       |   Package pl196x is already up-to-date!\n       | Downloading package porter_test to /usr/share/nltk_data...\n       |   Package porter_test is already up-to-date!\n       | Downloading package ppattach to /usr/share/nltk_data...\n       |   Package ppattach is already up-to-date!\n       | Downloading package problem_reports to\n       |     /usr/share/nltk_data...\n       |   Package problem_reports is already up-to-date!\n       | Downloading package product_reviews_1 to\n       |     /usr/share/nltk_data...\n       |   Package product_reviews_1 is already up-to-date!\n       | Downloading package product_reviews_2 to\n       |     /usr/share/nltk_data...\n       |   Package product_reviews_2 is already up-to-date!\n       | Downloading package propbank to /usr/share/nltk_data...\n       |   Package propbank is already up-to-date!\n       | Downloading package pros_cons to /usr/share/nltk_data...\n       |   Package pros_cons is already up-to-date!\n       | Downloading package ptb to /usr/share/nltk_data...\n       |   Package ptb is already up-to-date!\n       | Downloading package punkt to /usr/share/nltk_data...\n       |   Package punkt is already up-to-date!\n       | Downloading package punkt_tab to /usr/share/nltk_data...\n       |   Unzipping tokenizers/punkt_tab.zip.\n       | Downloading package qc to /usr/share/nltk_data...\n       |   Package qc is already up-to-date!\n       | Downloading package reuters to /usr/share/nltk_data...\n       |   Package reuters is already up-to-date!\n       | Downloading package rslp to /usr/share/nltk_data...\n       |   Package rslp is already up-to-date!\n       | Downloading package rte to /usr/share/nltk_data...\n       |   Package rte is already up-to-date!\n       | Downloading package sample_grammars to\n       |     /usr/share/nltk_data...\n       |   Package sample_grammars is already up-to-date!\n       | Downloading package semcor to /usr/share/nltk_data...\n       |   Package semcor is already up-to-date!\n       | Downloading package senseval to /usr/share/nltk_data...\n       |   Package senseval is already up-to-date!\n       | Downloading package sentence_polarity to\n       |     /usr/share/nltk_data...\n       |   Package sentence_polarity is already up-to-date!\n       | Downloading package sentiwordnet to /usr/share/nltk_data...\n       |   Package sentiwordnet is already up-to-date!\n       | Downloading package shakespeare to /usr/share/nltk_data...\n       |   Package shakespeare is already up-to-date!\n       | Downloading package sinica_treebank to\n       |     /usr/share/nltk_data...\n       |   Package sinica_treebank is already up-to-date!\n       | Downloading package smultron to /usr/share/nltk_data...\n       |   Package smultron is already up-to-date!\n       | Downloading package snowball_data to /usr/share/nltk_data...\n       |   Package snowball_data is already up-to-date!\n       | Downloading package spanish_grammars to\n       |     /usr/share/nltk_data...\n       |   Package spanish_grammars is already up-to-date!\n       | Downloading package state_union to /usr/share/nltk_data...\n       |   Package state_union is already up-to-date!\n       | Downloading package stopwords to /usr/share/nltk_data...\n       |   Package stopwords is already up-to-date!\n       | Downloading package subjectivity to /usr/share/nltk_data...\n       |   Package subjectivity is already up-to-date!\n       | Downloading package swadesh to /usr/share/nltk_data...\n       |   Package swadesh is already up-to-date!\n       | Downloading package switchboard to /usr/share/nltk_data...\n       |   Package switchboard is already up-to-date!\n       | Downloading package tagsets to /usr/share/nltk_data...\n       |   Package tagsets is already up-to-date!\n       | Downloading package tagsets_json to /usr/share/nltk_data...\n       |   Unzipping help/tagsets_json.zip.\n       | Downloading package timit to /usr/share/nltk_data...\n       |   Package timit is already up-to-date!\n       | Downloading package toolbox to /usr/share/nltk_data...\n       |   Package toolbox is already up-to-date!\n       | Downloading package treebank to /usr/share/nltk_data...\n       |   Package treebank is already up-to-date!\n       | Downloading package twitter_samples to\n       |     /usr/share/nltk_data...\n       |   Package twitter_samples is already up-to-date!\n       | Downloading package udhr to /usr/share/nltk_data...\n       |   Package udhr is already up-to-date!\n       | Downloading package udhr2 to /usr/share/nltk_data...\n       |   Package udhr2 is already up-to-date!\n       | Downloading package unicode_samples to\n       |     /usr/share/nltk_data...\n       |   Package unicode_samples is already up-to-date!\n       | Downloading package universal_tagset to\n       |     /usr/share/nltk_data...\n       |   Package universal_tagset is already up-to-date!\n       | Downloading package universal_treebanks_v20 to\n       |     /usr/share/nltk_data...\n       |   Package universal_treebanks_v20 is already up-to-date!\n       | Downloading package vader_lexicon to /usr/share/nltk_data...\n       |   Package vader_lexicon is already up-to-date!\n       | Downloading package verbnet to /usr/share/nltk_data...\n       |   Package verbnet is already up-to-date!\n       | Downloading package verbnet3 to /usr/share/nltk_data...\n       |   Unzipping corpora/verbnet3.zip.\n       | Downloading package webtext to /usr/share/nltk_data...\n       |   Package webtext is already up-to-date!\n       | Downloading package wmt15_eval to /usr/share/nltk_data...\n       |   Unzipping models/wmt15_eval.zip.\n       | Downloading package word2vec_sample to\n       |     /usr/share/nltk_data...\n       |   Package word2vec_sample is already up-to-date!\n       | Downloading package wordnet to /usr/share/nltk_data...\n       |   Package wordnet is already up-to-date!\n       | Downloading package wordnet2021 to /usr/share/nltk_data...\n       | Downloading package wordnet2022 to /usr/share/nltk_data...\n       |   Unzipping corpora/wordnet2022.zip.\n       | Downloading package wordnet31 to /usr/share/nltk_data...\n       | Downloading package wordnet_ic to /usr/share/nltk_data...\n       |   Package wordnet_ic is already up-to-date!\n       | Downloading package words to /usr/share/nltk_data...\n       |   Package words is already up-to-date!\n       | Downloading package ycoe to /usr/share/nltk_data...\n       |   Package ycoe is already up-to-date!\n       | \n     Done downloading collection all-nltk\n\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-6e230a00a763>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;31m# function should make a new copy of self to use?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             self._simple_interactive_menu(\n\u001b[1;32m   1005\u001b[0m                 'd) Download', 'l) List', ' u) Update', 'c) Config', 'h) Help', 'q) Quit')\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloader> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}],"execution_count":46},{"cell_type":"code","source":"import nltk\n\n# Download the necessary NLTK data\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:41:24.838730Z","iopub.execute_input":"2025-03-20T18:41:24.839115Z","iopub.status.idle":"2025-03-20T18:41:24.848899Z","shell.execute_reply.started":"2025-03-20T18:41:24.839087Z","shell.execute_reply":"2025-03-20T18:41:24.847580Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"import nltk\n\n# Try downloading the necessary NLTK resources\ntry:\n    nltk.data.find('corpora/stopwords')\nexcept LookupError:\n    nltk.download('stopwords')\n\ntry:\n    nltk.data.find('corpora/wordnet')\nexcept LookupError:\n    nltk.download('wordnet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:41:49.325075Z","iopub.execute_input":"2025-03-20T18:41:49.325455Z","iopub.status.idle":"2025-03-20T18:41:49.333008Z","shell.execute_reply.started":"2025-03-20T18:41:49.325395Z","shell.execute_reply":"2025-03-20T18:41:49.332000Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"import nltk\n\n# Try downloading the necessary NLTK resources\ntry:\n    nltk.data.find('corpora/stopwords')\nexcept LookupError:\n    nltk.download('stopwords')\n\ntry:\n    nltk.data.find('corpora/wordnet')\nexcept LookupError:\n    nltk.download('wordnet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:43:34.430159Z","iopub.execute_input":"2025-03-20T18:43:34.430620Z","iopub.status.idle":"2025-03-20T18:43:34.440203Z","shell.execute_reply.started":"2025-03-20T18:43:34.430585Z","shell.execute_reply":"2025-03-20T18:43:34.439029Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"import spacy\nimport re\n\n# Load the small English model\nnlp = spacy.load('en_core_web_sm')\n\n# Preprocessing Function using spaCy\ndef preprocess_text_spacy(text):\n    # Lowercase the text\n    text = text.lower()\n    \n    # Remove special characters and digits\n    text = re.sub(r'[^a-z\\s]', '', text)\n    \n    # Process the text with spaCy\n    doc = nlp(text)\n    \n    # Remove stopwords and apply lemmatization\n    words = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n    \n    return ' '.join(words)\n\n# Apply preprocessing to the title and text columns\ntrain_title_df = train_df[\"title\"].apply(preprocess_text_spacy)\ntrain_text_df = train_df[\"text\"].apply(preprocess_text_spacy)\ntest_title_df = test_df[\"title\"].apply(preprocess_text_spacy)\ntest_text_df = test_df[\"text\"].apply(preprocess_text_spacy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:44:41.986280Z","iopub.execute_input":"2025-03-20T18:44:41.986734Z","iopub.status.idle":"2025-03-20T19:41:29.344902Z","shell.execute_reply.started":"2025-03-20T18:44:41.986704Z","shell.execute_reply":"2025-03-20T19:41:29.342319Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# Use n-grams (bigrams/trigrams) in TF-IDF\nvectorizer = TfidfVectorizer(max_features=100000, ngram_range=(1, 2))\n\n# Fit the vectorizer on the training data and transform the test data\ntrain_title_df_tfidf = vectorizer.fit_transform(train_title_df)\ntest_title_df_tfidf = vectorizer.transform(test_title_df)\n\ntrain_text_df_tfidf = vectorizer.fit_transform(train_text_df)\ntest_text_df_tfidf = vectorizer.transform(test_text_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Initialize Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model using title TF-IDF features\nrf_model.fit(train_title_df_tfidf, y_train)\n\n# Make predictions\nrf_predictions = rf_model.predict(test_title_df_tfidf)\n\n# Calculate accuracy\nrf_accuracy = accuracy_score(y_test, rf_predictions)\nprint(\"Random Forest Test Accuracy:\", rf_accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Initialize XGBoost\nxgb_model = XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.05)\n\n# Train the model using title TF-IDF features\nxgb_model.fit(train_title_df_tfidf, y_train)\n\n# Make predictions\nxgb_predictions = xgb_model.predict(test_title_df_tfidf)\n\n# Calculate accuracy\nxgb_accuracy = accuracy_score(y_test, xgb_predictions)\nprint(\"XGBoost Test Accuracy:\", xgb_accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from catboost import CatBoostClassifier\n\n# Initialize CatBoost\ncatboost_model = CatBoostClassifier(iterations=1000, depth=10, learning_rate=0.05, loss_function='Logloss', verbose=200)\n\n# Train the model using title TF-IDF features\ncatboost_model.fit(train_title_df_tfidf, y_train)\n\n# Make predictions\ncatboost_predictions = catboost_model.predict(test_title_df_tfidf)\n\n# Calculate accuracy\ncatboost_accuracy = accuracy_score(y_test, catboost_predictions)\nprint(\"CatBoost Test Accuracy:\", catboost_accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}